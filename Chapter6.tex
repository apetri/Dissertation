%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{An application to real data: the CFHTLenS galaxy survey}
\lhead[\fancyplain{}{\thepage}]{\fancyplain{}{\rightmark}}
 \thispagestyle{plain}
\setlength{\parindent}{10mm}

\label{chp:6}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this Chapter we present an application of the techniques presented so far to real data, contained in the publicly available CFHTLenS survey catalogs \citep{cfht1,cfht2,CFHTKilbinger}. We start by reviewing the data reduction procedure that bridges the gap between the row--ordered data to the reconstructed $\kappa$ maps. We then present a set of cosmological simulations tailored to the CFHTLenS catalogs, which allow us to build the feature emulator used to produce $\Lambda$CDM parameter inferences.   

\section{Catalogs}
The CFHTLenS survey covers an area of 154\,${\rm deg}^2$, divided in four sub--patches of size 64,23,44 and 23\,${\rm deg}^2$. The publicly released catalogs, created with the SExtractor software \citep{SExtractor}, contain information on  galaxy photometric redshifts (see \citep{cfhtPhoto} for a detail on the estimation procedure) and shapes extracted with \ttt{lensfit} \citep{cfht1,cfht2}. After applying a redshift cut $0.2<z<1.3$ on the galaxies, and after considering only the ones with positive weight w (larger w indicates smaller shape measurement uncertainty), we are left with roughly $N_g=4.2$\,million objects distributed over an area of 124.7\,${\rm deg}^2$. This corresponds to an average galaxy density of $n_g\approx 9.3\,{\rm galaxies/arcmin}^2$. The catalog size is further reduced by $25\%$ if sub--patches with non negligible star--galaxy correlations are rejected \citep{CFHTFu}. These correlations are caused by imperfect Point Spread Function (PSF) removal procedures. With the information contained in the publicly available catalogs, we can construct the CFHTLenS $\kappa$ maps using the KS procedure (\ref{eq:2:kappa-ks}) applied to the ellipticity estimated shear data. We create smooth ellipticity maps according to \citep{PetriCFHTMink,PetriCFHTPeaks}

\begin{equation}
\label{eq:6:ellip-smooth}
\bar{\bb{e}}(\pt) = \frac{\sum_{i=1}^{N_g}W(\vert\pt-\pt_i\vert){\rm w}_i(\bb{e}_i -\bb{c}_i)}{\sum_{i=1}^{N_g}W(\vert\pt-\pt_i\vert){\rm w}_i(1+m_i)}
\end{equation}
%
In equation (\ref{eq:6:ellip-smooth}), $\pt_i,{\rm w}_i,\bb{e}_i,\bb{c}_i,m_i$ refer, respectively, to the sky position, weight, observed ellipticity, additive and multiplicative ellipticity correction of the $i$--th galaxy as read from the catalog. A Gaussian smoothing window

\begin{equation}
\label{eq:6:gausswin}
W(\pt) = \frac{1}{2\pi\theta_G^2}\exp\left(-\frac{\theta^2}{2\theta_G^2}\right)
\end{equation}
%
has been applied to the reconstructed images. The window size $\theta_G$ has been fixed to 1$'$, and occasionally varied to 1.8$'$ and 3.5$'$ for testing purposes, described later in the Chapter. We then set $\pmb{\gamma}(\pt)=\bar{\bb{e}}(\pt)$ and use equation (\ref{eq:2:kappa-ks}) to construct the $\kappa$ images which will then be used for the parameter inferences. We divide the survey area in 13 square sub--fields of area $12\,{\rm deg}^2$. We sample each subfield with $512^2$ evenly spaced square pixels. The reduced data undergoes a feature extraction step (see Chapter \ref{chp:4}). The extracted features are then compared to the simulated ones in a Bayesian fashion (see Chapter \ref{chp:5}) to obtain $\Lambda$CDM parameter posterior distributions. In the next section we describe the simulations used for the construction of the CFHTLenS feature emulator.      

\section{Emulator}
In order to build a feature emulator for CFHTLenS, we need to know how the particular feature depends on the cosmological parameters. We sample the $\Lambda$CDM parameter space using $N_M$ points and we ran the simulation pipeline described in \S~\ref{sec:3:lt} on each of the sampled points. We then measure the mean feature in each sampled cosmology and we infer the mean feature for arbitrary cosmologies (not included in the $N_M$ samples) using a suitable interpolation procedure. 

\subsection{Cosmological parameter sampling}
\label{sec:6:sampling}
We describe the procedure we used to sample the $\Lambda$CDM parameter space. We consider a subset of $N_\pi=3$ parameters $\bb{p}=(\Omega_m,w_0,\sigma_8)$ and we seek a way to uniformly sample it so that no parameter is repeated twice. This sampling scheme takes the name of \textit{latin hypercube} \citep{Coyote2}. One way to implement the latin hypercube sample in practice is to set a $N_\pi$--dimensional bounding box that will contain all the sampled points, and normalize it to $[0,1]^{N_\pi}$ for simplicity. We can then set the number $N_M$ of cosmological models we wish to sample and distribute in an uniform latin hypercube scheme. Following \citep{Coyote2,PetriCFHTMink} we define a cost function 

\begin{equation}
\label{eq:6:cost}
\mathcal{C}(\bb{P}) = \frac{2{N_\pi}^{1/2}}{N_M(N_M-1)}\sum_{i<j} \frac{1}{\vert \bb{P}_i-\bb{P}_j \vert}
\end{equation} 
%
where $\bb{P}$ is a $N_M\times N_\pi$ matrix that contains the information on the sampled points and the sum runs over all pair of points. In order to sample the hypercube uniformly, we seek a configuration $\bb{P}$ that minimizes the cost function (\ref{eq:6:cost}) while enforcing the latin hypercube constraint. Because $\mathcal{C}$ is effectively the Coulomb potential energy of $N_M$ unit point charges confined in a box, its minimum leads to a uniform configuration. The simplest latin hypercube arrangement corresponds to the diagonal design $\bb{P}^0$, in which the points are arranged on the diagonal of the hypercube

\begin{equation}
\label{eq:6:diagonal}
\bb{P}^0_{i} = \frac{i}{N_M}\underbrace{(1,1,...,1)}_{N_\pi}
\end{equation}
%  
Of course this trivial arrangement is far from optimal. A possible heuristic method to find out a configuration $\bb{P}$ that minimizes (\ref{eq:6:cost}) is simulated annealing \citep{Skiena}, which however is too computationally expensive for our purposes. We resort on this less accurate, but faster, heuristic scheme instead: 
\begin{enumerate}
\item Start from the diagonal design $\bb{P}^0$
\item Pick a random pair of points $(i,j)$ among the $N_M(N_M-1)/2$ available, pick a random parameter $p$ among the $N_\pi$ available
\item Swap $P_{ip}$ with $P_{jp}$ (the swap preserves the latin hypercube property), recompute the cost function $\mathcal{C}$
\item If the cost decreases, keep the swap, otherwise revert to the previous configuration
\item Re--iterate the procedure starting from point 2. 
\end{enumerate}
%
\begin{figure}
\begin{center}
\includegraphics[scale=0.4]{Figures/eps/cfht_design.eps}
\end{center}
\caption{Distribution of the $(\Omega_m,w_0,\sigma_8)$ sampled triplets in the parameter prior box. We show both the $(\Omega_m,w_0)$ (left) and the $(\Omega_m,\sigma_8)$ (right) projections. The black points correspond to the $N_M=91$ latin hypercube models, and the red cross correspond to the fiducial $\Lambda$CDM parameters shown in Table \ref{tab:1:cosmopar}. The design is the result of $10^5$ iterations of the heuristic procedure described in \S~\ref{sec:6:sampling}.}
\label{fig:6:sampling}
\end{figure}
%
After several iterations, we are left with a latin hypercube design which samples the parameter space approximately uniformly. The last step is to rescale the parameter coordinates from the $[0,1]$ bounds to their originally intended values. The latin hypercube design we use for the present analysis is shown in Figure \ref{fig:6:sampling}. 

\subsection{Simulations}
We run one $N$--body simulation with $N_p=512^3$, $L_b=240\,{\rm Mpc}/h$ for each of the cosmologies shown in Figure \ref{fig:6:sampling}. All these simulations (referred to as \ttt{CFHTemu1} in the remainder of this work) share the seed used to generate the initial conditions. In addition we run 50 independent $N$--body simulations (referred to as \ttt{CFHTcov} in the remainder of this work) for the fiducial cosmology indicated by the red cross in Figure \ref{fig:6:sampling}. This fiducial dataset will be used to estimate feature covariance matrices. We generate WL shear catalogs using the \LT\, software, performing ray--tracing from the galaxy positions and to the galaxy redshifts contained in the CFHTLenS catalog. In order to forward model the observations correctly, we need to add the intrinsic galaxy ellipticity to the WL signal obtained from ray--tracing. This can be done looking at the CFHTLenS catalog itself, assuming that the WL signal contained in the observations is much smaller than the intrinsic ellipticity noise. We take the intrinsic complex ellipticity $e$ of each galaxy and we rotate it by a random angle $\phi$ by performing the substitution

\begin{equation}
\label{eq:6:randrot}
e \rightarrow e\exp(2i\phi)
\end{equation} 
%
We then add this intrinsic ellipticity to the simulated WL shear. The random rotation prevents the double counting of the WL signal, whose spatial coherence is destroyed by the rotation. We use the forward modeled catalogs 

\begin{equation}
\label{eq:6:forwardcatalog}
e(\bb{p}) = \gamma(\bb{p}) + e\exp(2i\phi)
\end{equation}
%
to perform the KS inversion and the consequent feature extraction.      

\subsection{Interpolation}
The \LT\, simulation pipeline described in \S~\ref{sec:3:lt}, coupled with the parameter sampling heuristic described in \S~\ref{sec:6:sampling}, allows us to construct the $N_M\times N_d$ feature matrix $\bb{D}$ (introduced in \S~\ref{sec:5:dimred}), which contains information about the mean feature in each of the $N_M$ sampled cosmologies. 
%
\begin{figure}
\begin{center}
\includegraphics[scale=0.4]{Figures/eps/cfht_emulator_accuracy.eps}
\end{center}
\caption{Emulator accuracy test for the CFHTLenS $\kappa$ power spectrum $P_{\kappa\kappa}$ (red) and Minkowski functionals $V_k$ (green, blue, black). We use the \ttt{CFHTemu1} simulations to produce a feature emulator that is then tested against the mean feature measured in the \ttt{CFHTcov} simulations (solid lines). We also compare the mean \ttt{CFHTcov} feature to an emulated feature with $(\Omega_m,w_0\sigma_8)=(0.8,-1.0,0.5)$ (deshed lines). The differences are plotted in units of the statistical error on each feature bin.}
\label{fig:6:interpolation}
\end{figure}
%
We can use the information contained in $\bb{D}$ to infer the mean feature in an arbitrary cosmology, not necessarily included in the $N_M$ samples. Although several sophisticated procedures can be adopted (see \citep{Coyote2}), for the purpose of this analysis we found it convenient to adopt a Radial Basis Functions (RBF) interpolation scheme. We model the cosmology dependence of the feature $\bb{d}$ as

\begin{equation}
\label{eq:6:rbf}
d_i(\bb{p}) = \sum_{j=1}^{N_M} \lambda_{ij}f(\vert\bb{p}-\bb{p}_j\vert;R)
\end{equation}  
%
where $\bb{p}_i$ is the $i$--th sampled $\Lambda$CDM parameter tuple and $f$ is the multiquadric function

\begin{equation}
\label{eq:6:multiquadric}
f(x;R) = \sqrt{1+\left(\frac{x}{R}\right)^2}
\end{equation}
%
We chose the smoothing scale $R$ as the average distance between sample parameters

\begin{equation}
\label{eq:6:scale}
R = \frac{2}{N_M(N_M-1)}\sum_{i<j}\vert\bb{p}_i-\bb{p}_j\vert
\end{equation} 
%
The interpolation can be performed for an arbitrary cosmology $\bb{p}$ once the weights $\lambda_{ij}$ are specified. This can be done by enforcing the constraint $d_i(\bb{p}_j) = D_{ji}$ for each index pair $(i,j)$. This leads to 

\begin{equation}
\label{eq:6:weights}
\pmb{\lambda} = [\bb{f}(R)^{-1}\bb{D}]^T
\end{equation} 
%
where we defined $f_{ij}(R) \equiv f(\vert\bb{p}_i-\bb{p}_j;R\vert)$. A test on the accuracy of the so obtained feature emulator $\bb{d}(\bb{p})$ is displayed in Figure \ref{fig:6:interpolation}. We use the emulated feature $\bb{d}(\bb{p})$ as the forward model that enters the Bayesian parameter inference defined by equation (\ref{eq:5:bayesthm}). 



\section{$\Lambda$CDM parameter inference}

\subsection{PCA projection}

\subsection{Density fluctuations}

\subsection{Dark Energy}


\bibliography{ref}