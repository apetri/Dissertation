%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Cosmological parameter inference}
\lhead[\fancyplain{}{\thepage}]{\fancyplain{}{\rightmark}}
 \thispagestyle{plain}
\setlength{\parindent}{10mm}
\label{chp:5}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this Chapter we give an overview and discuss the cosmological parameter inference techniques used in this work. Inferring $\Lambda$CDM parameters from observations requires the construction of $\kappa$ images from $\pmb{\gamma}$ catalogs and the measurement of a feature $\bb{d}$ from the reconstructed image. When a forward model $\bb{d}(\bb{p})$ that connects features to cosmological parameters $\bb{p}$ is available, an estimate of the parameters $\bbh{p}$ can be derived from an estimate of the feature $\bbh{d}$ in a Bayesian framework. In this Chapter we review the probabilistic framework and we study WL parameter constraining capabilities using the features discussed in Chapter \ref{chp:4}. We also discuss a variety of constraint degradation sources and propose possible remedies.    

\section{Bayesian formalism}
In this paragraph we review the Bayesian probabilistic framework that we base the parameter inference on. We denote with $\bb{d}$ an $N_b$--dimensional image feature and with $\bb{p}$ a $N_\pi$ dimensional tuple of $\Lambda$CDM cosmological parameters (see Table \ref{tab:1:cosmopar}). We also indicate as $\bbh{d}$ an estimate of a feature from a simulated $\kappa$ field of view, as $\dobs$ a measured feature from an actual observation and as $\bbh{p}$ the deriving parameter estimate. We assume the existence of a forward model $\bb{d}(\bb{p})$ which can be obtained using our WL simulation pipeline or, in special cases such as for the $\kappa$ power spectrum, using analytical codes such as NICAEA \citep{Nicaea}. Using Bayes theorem, the likelihood $\lik{\bbh{p}}{\dobs}$ of an estimate $\bbh{p}$ given an observation $\dobs$ is given by

\begin{equation}
\label{eq:5:bayesthm}
\lik{\bbh{p}}{\dobs,\bb{d}(\bb{p})} = \frac{\lik{\dobs}{\bbh{p},\bb{d}(\bb{p})}\Pi(\bbh{p})}{\mathcal{L}(\dobs)}
\end{equation}
%
In the notation of equation (\ref{eq:5:bayesthm}) $\Pi$ encodes prior information on the parameters coming from WL independent probes (such as CMB experiments for example) and $\mathcal{L}(\dobs)$ is the overall observation likelihood, which acts as a $\bb{p}$--independent normalization factor in the parameter likelihood, which we will ignore in the prosecution of this work. We make a Gaussian assumption for the feature likelihood 

\begin{equation}
\label{eq:5:gaussfeatlik}
\lik{\dobs}{\bbh{p},\bb{d}(\bb{p})} = \frac{1}{(2\pi)^{N_b/2}\vert\bb{C}\vert}\exp\left(-\frac{1}{2}(\dobs-\bb{d}(\bb{p}))^T\bb{C}^{-1}(\dobs-\bb{d}(\bb{p}))\right) 
\end{equation}
%
where $\bb{C}$ is a $\bb{p}$--independent feature--feature covariance matrix. The Gaussian assumption for the data likelihood is justified by the Central Limit Theorem applied to feature averaging over a large number of fields of view, which can be as high as $O(10^3)$ for a $\theta_{\rm FOV}=3.5\,{\rm deg}$ sized tiling of a modern galaxy survey such as LSST. The independence of the covariance matrix $\bb{C}$ on the cosmological parameters is not justified in the present work. The drawbacks of such assumption will be reserved for future investigation. 

Once the parameter likelihood is known, parameter confidence intervals can be obtained looking at surfaces with constant $\mathcal{L}$ in $\bb{p}$ space. We define an $N\sigma$ parameter confidence interval as the $\bb{p}$ space region with $\mathcal{L}>\mathcal{L}_N$. The likelihood confidence levels are defined as 

\begin{equation}
\label{eq:5:liklevel}
\int_{\mathcal{L}>\mathcal{L}_N}\lik{\bbh{p}}{\dobs,\bb{d}(\bb{p})} d\bbh{p} = \frac{1}{\sqrt{2\pi}}\int_{-N}^Ne^{-x^2/2}dx
\end{equation}  
%
Note that this definition of $N\sigma$ confidence intervals corresponds to the commonly accepted one when $\mathcal{L}(\bbh{p})$ is Gaussian. If this is the case, calling $\bbh{p}_0$ the location of the likelihood peak, the matrix $\bb{\Sigma}$, defined by

\begin{equation}
\label{eq:5:parcov}
\left(\Sigma^{-1}\right)_{\alpha\beta} = -\left(\frac{\partial^2\log\mathcal{L}(\bbh{p})}{\partial\h{p}_\alpha\partial\h{p}_\beta}\right)_{\bbh{p}=\bbh{p}_0}
\end{equation}
%
is the parameter covariance matrix. We observe that, even if the parameter likelihood is not Gaussian, we can use the peak location $\bbh{p}_0$ and the matrix (\ref{eq:5:parcov}) as an estimate of the parameters and their covariance, although a complete characterization of the parameter space through the confidence intervals defined in (\ref{eq:5:liklevel}) is preferred. The confidence intervals can be calculated by drawing samples from $\mathcal{L}(\bbh{p})$ using Markov Chain Monte Carlo (MCMC) techniques, which are implemented by many convenient software packages (see for example \citep{emcee}). 

\subsection{Fisher matrix approximation}
Parameter inference becomes simpler if the forward model $\bb{d}(\bb{p})$ is linear in the parameters. Linearity can be safely assumed in the limit in which confidence intervals are expected to be localized around the peak of the likelihood, which is the case for large scale WL surveys. We can write 

\begin{equation}
\label{eq:5:linapprox}
\bb{d}(\bb{p}) = \bb{d}_0 + \bb{M}(\bb{p}-\bb{p}_0) + O(\vert\bb{p}-\bb{p}_0\vert^2)
\end{equation}          
%
Assuming a flat prior $\Pi(\bbh{p})$ and plugging (\ref{eq:5:linapprox}) into (\ref{eq:5:gaussfeatlik}) we get, for the $\bb{p}$--dependent part of the likelihood

\begin{equation}
\label{eq:5:linapprox-lik}
-2\log\mathcal{L}(\bb{p}) = \left[\dobs-\bb{d}_0-\bb{M}(\bb{p}-\bb{p}_0)\right]^T\bb{\Psi}\left[\dobs-\bb{d}_0-\bb{M}(\bb{p}-\bb{p}_0)\right]
\end{equation}
%
From (\ref{eq:5:linapprox-lik}) we can immediately get an estimate for the peak of the likelihood $\bbh{p}_0$ and for the parameter covariance $\bb{\Sigma}$ using (\ref{eq:5:parcov})

\begin{equation}
\label{eq:5:linapprox-peak}
\bbh{p}_0 = \bb{p}_0 + \left(\bb{M}^T\bb{\Psi}\bb{M}\right)^{-1}\bb{M}^T\bb{\Psi}\left(\dobs-\bb{d}_0\right)
\end{equation}
%
\begin{equation}
\label{eq:5:linapprox-cov}
\bb{\Sigma} = \bb{F}^{-1} \equiv \left(\bb{M}^T\bb{\Psi}\bb{M}\right)^{-1} 
\end{equation}
%
Equations (\ref{eq:5:linapprox-peak}), (\ref{eq:5:linapprox-cov}) constitute an important result which takes the name of Fisher matrix approximation, and $\bb{F}\equiv\bb{M}^T\bb{\Psi}\bb{M}$ takes the name of Fisher information matrix. In the case where prior information on the parameters is available, the estimates for the likelihood peak and parameter covariance are modified. For a Gaussian prior with distribution

\begin{equation}
\label{eq:5:gaussprior}
\Pi(\bb{p}) = \frac{\vert\bb{F}_\Pi\vert}{(2\pi)^{N_\pi/2}}\exp\left(-\frac{1}{2}(\bb{p}-\bb{p}_\Pi)^T\bb{F}_\Pi(\bb{p}-\bb{p}_\Pi)\right)
\end{equation}
%
we have 

\begin{equation}
\label{eq:5:linapprox-peak-prior}
\bbh{p}_0 = \left(\bb{F}+\bb{F}_\Pi\right)^{-1}\left[\bb{F}_\Pi\bb{p}_\Pi + \bb{F}\bb{p}_0 + \bb{M}^T\bb{\Psi}(\bbh{d}-\bb{d}_0) \right]
\end{equation}
%
\begin{equation}
\label{eq:5:linapprox-cov-prior}
\bb{\Sigma} = \left(\bb{F}+\bb{F}_\Pi\right)^{-1} 
\end{equation}
%
Equation (\ref{eq:5:linapprox-cov-prior}) simply states that, because the parameter prior is independent from the WL observation, parameter error bars add as their inverse squared weight. In the case in which the parameter likelihood and prior peak at the same location $\bb{p}_0=\bb{p}_\Pi$, equation (\ref{eq:5:linapprox-peak-prior}) reduces to (\ref{eq:5:linapprox-peak}) with a modified Fisher information $\bb{F}+\bb{F}_\Pi$.    

\section{Error degradation induced by covariance noise}
In the previous derivation of parameter estimates (\ref{eq:5:linapprox-peak}) and error bars based on the covariance (\ref{eq:5:linapprox-cov}) we have assumed perfect knowledge of the feature--feature covariance matrix $\bb{C}$ and its inverse $\bb{\Psi}$. Although smooth models exist for covariances of power spectra (see (\ref{eq:4:powercov-gauss}) for an example in the Gaussian case), the same is not true for more complicated features, such as the ones described in Chapter \ref{chp:4}. What we are forced to do, in practice, is to obtain an estimate $\bbh{C}$ of $\bb{C}$ from our simulations and to plug the estimate this estimate feature likelihood (\ref{eq:5:gaussfeatlik}). The uncertainties in $\bbh{C},\bbh{\Psi}$ carry over all the way to the parameter estimate $\bbh{p}_0$ and covariance $\bb{\Sigma}$, of which we are left with a noisy estimate $\bbh{\Sigma}$. If simulations and observations are uncorrelated, the parameter estimate $\bbh{p}_0$ is unbiased (within the limits of the linear approximation (\ref{eq:5:linapprox})). The parameter covariance estimator

\begin{equation}
\label{eq:5:pcov-est-1}
\bbh{\Sigma}_1 = \bbh{F}^{-1}
\end{equation}
%
is a biased estimate of $\bb{\Sigma}$ as we will see later in the Chapter. The unbiased version of (\ref{eq:5:pcov-est-1}) is the correct error--bar to assign to $\bbh{p}_0$ if the scatter of the estimator (\ref{eq:5:linapprox-peak}) corresponds to $\Sigma$. Unfortunately we are going to see that this is not true. The real scatter of (\ref{eq:5:linapprox-peak}), assuming $\langle\dobs-\bb{d}_0\rangle=0$ for simplicity, is given by

\begin{equation}
\label{eq:5:peak-scatter}
\left\langle\delta\bbh{p}_0\delta\bbh{p}_0^T\right\rangle = \left\langle\bbh{F}^{-1}\bb{M}^T\bbh{\Psi}(\dobs-\bb{d}_0)(\dobs-\bb{d}_0)^T\bbh{\Psi}\bb{M}\bbh{F}^{-1}\right\rangle
\end{equation}
%
where the expectation value has to be taken both with respect to the observations and the simulations, both affected by noise, but assumed uncorrelated. To have an idea of the magnitude of (\ref{eq:5:peak-scatter}), we can take the expectation value over the observation and focus ourselves on the uncertainty introduced by the noise in the simulations only. We will use 

\begin{equation}
\label{eq:5:expobs}
\left\langle(\dobs-\bb{d}_0)(\dobs-\bb{d}_0)^T\right\rangle = \bb{C}
\end{equation}
%
to produce a noisy estimate of the $\bbh{p}_0$ scatter $\bbh{\Sigma}_2$, defined as 

\begin{equation}
\label{eq:5:pcov-est-2}
\bbh{\Sigma}_2 = \bbh{F}^{-1}\bb{M}^T\bbh{\Psi}\bb{C}\bbh{\Psi}\bb{M}\bbh{F}^{-1} 
\end{equation} 
%
In the next section we are going to show how expectation values of (\ref{eq:5:pcov-est-1}), (\ref{eq:5:pcov-est-2}) over simulations can be calculated under a Gaussian assumption.    

\subsection{Covariance matrix estimation}
To produce estimates of the feature--feature covariance matrix $\bb{C}$, we use our simulation pipeline, described in Chapter \ref{chp:3}, to produce multiple pseudo--independent realizations of a $\kappa$ field of view. We measure the feature $\bbh{d}_r$ from each image using the techniques exposed in Chapter \ref{chp:4} and we produce a covariance estimator $\bbh{C}$ based on ensembles made of a high number $N_r$ of image realizations

\begin{equation}
\label{eq:5:meanest-sim}
\bbh{d}_{\rm mean} = \frac{1}{N_r}\sum_{r=1}^{N_r}\bbh{d}_r 
\end{equation}
%
\begin{equation}
\label{eq:5:covestest-sim}
\bbh{C} = \frac{1}{n}\sum_{r=1}^{N_r}\left(\bbh{d}_r-\bbh{d}_{\rm mean}\right)^T\left(\bbh{d}_r-\bbh{d}_{\rm mean}\right) 
\end{equation}
%
We indicated as $n=N_r-1$ the effective number of degrees of freedom in the ensemble, which is smaller than $N_r$ because the mean feature $\bbh{d}_{\rm mean}$ is not known and has to be estimated from the ensemble itself. If the feature estimate $\bbh{d}_r$ is drawn from a Gaussian distribution with covariance $\bb{C}$, the covariance estimate $\bbh{C}$ is distributed according to the Wishart probability distribution \citep{Taylor12,Taylor14,MasumotoWishart}. A functional form for the Wishart distribution $\lik{\bbh{C}}{\bb{C},n}$ can be obtained from its characteristic function 

\begin{equation}
\label{eq:5:chardef}
\phi(\bb{J}) = \left\langle e^{i\Tr(\bb{J}\bbh{C})}\right\rangle
\end{equation}
%
Performing an inverse Fourier transform in matrix space (much like the one in (\ref{eq:4:characteristic-inverse})), we can reconstruct $\lik{\bbh{C}}{\bb{C},n}$ from $\phi(\bb{J})$. The characteristic function $\phi$ can be evaluated from the moments of the Wishart distribution which are easily expressed in terms of $\bb{C}$ and $n$ via a straightforward though tedious procedure. The final result is (see \citep{Taylor12} for the details)

\begin{equation}
\label{eq:5:charw}
\phi(\bb{J}) = \left\vert\mathds{1}_{N_b\times N_b}-\frac{2i\bb{JC}}{n}\right\vert^{-n/2}
\end{equation}
%
The inverse Fourier transform leads to the functional form of the Wishart distribution

\begin{equation}
\label{eq:5:wishart}
\lik{\bbh{C}}{\bb{C},n} = 
\end{equation}

\subsection{Perturbative calculation of the estimate scatter}

\section{Dimensionality reduction}

\section{Born approximation induced bias}

\section{Weak Lensing constraining power}

\bibliography{ref}